{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1  # alter the negative lable to be -1\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test data\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb7906ff610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0):\n",
    "        self.clf_num = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def init_args(self, datasets, labels):\n",
    "        \n",
    "        self.X = datasets\n",
    "        self.Y = labels\n",
    "        self.M, self.N = datasets.shape\n",
    "        \n",
    "        # set of weaks clfs\n",
    "        self.clf_sets = []\n",
    "        \n",
    "        # initialize the weights\n",
    "        self.weights = [1.0/self.M]*self.M\n",
    "        \n",
    "        # coefficience alpha of G(x) - GLM\n",
    "        self.alpha = [] \n",
    "        \n",
    "    def _G(self, features, labels, weights):\n",
    "        m = len(features)\n",
    "        error = 100000.0 # infinitely large\n",
    "        best_v = 0.0\n",
    "        # uni-dimensional features\n",
    "        features_min = min(features)\n",
    "        features_max = max(features)\n",
    "        n_step = (features_max - features_min + self.learning_rate) // self.learning_rate\n",
    "        # print('n_step:{}'.format(n_step))\n",
    "        direct, compare_array = None, None\n",
    "        for i in range(1, int(n_step)):\n",
    "            v = features_min + self.learning_rate * i\n",
    "            \n",
    "            if v not in features:\n",
    "                # computation of misclassification\n",
    "                compare_array_positive = np.array([1 if features[k] > v else -1 for k in range(m)])\n",
    "                weight_error_positive = sum([weights[k] for k in range(m) if compare_array_positive[k] != labels[k]])\n",
    "                \n",
    "                compare_array_nagetive = np.array([-1 if features[k] > v else 1 for k in range(m)])\n",
    "                weight_error_nagetive = sum([weights[k] for k in range(m) if compare_array_nagetive[k] != labels[k]])\n",
    "\n",
    "                if weight_error_positive < weight_error_nagetive:\n",
    "                    weight_error = weight_error_positive\n",
    "                    _compare_array = compare_array_positive\n",
    "                    direct = 'positive'\n",
    "                else:\n",
    "                    weight_error = weight_error_nagetive\n",
    "                    _compare_array = compare_array_nagetive\n",
    "                    direct = 'nagetive'\n",
    "                    \n",
    "                # print('v:{} error:{}'.format(v, weight_error))\n",
    "                if weight_error < error:\n",
    "                    error = weight_error\n",
    "                    compare_array = _compare_array\n",
    "                    best_v = v\n",
    "        return best_v, direct, error, compare_array\n",
    "        \n",
    "    # compute the alpha\n",
    "    def _alpha(self, error):\n",
    "        return 0.5 * np.log((1-error)/error)\n",
    "    \n",
    "    # normalization factor\n",
    "    def _Z(self, weights, a, clf):\n",
    "        return sum([weights[i]*np.exp(-1*a*self.Y[i]*clf[i]) for i in range(self.M)])\n",
    "        \n",
    "    # update the weight\n",
    "    def _w(self, a, clf, Z):\n",
    "        for i in range(self.M):\n",
    "            self.weights[i] = self.weights[i]*np.exp(-1*a*self.Y[i]*clf[i])/ Z\n",
    "    \n",
    "    # linear combination of G(x)\n",
    "    def _f(self, alpha, clf_sets):\n",
    "        pass\n",
    "    \n",
    "    def G(self, x, v, direct):\n",
    "        if direct == 'positive':\n",
    "            return 1 if x > v else -1 \n",
    "        else:\n",
    "            return -1 if x > v else 1 \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.init_args(X, y)\n",
    "        \n",
    "        for epoch in range(self.clf_num):\n",
    "            best_clf_error, best_v, clf_result = 100000, None, None\n",
    "            # select clf with smallest error\n",
    "            for j in range(self.N):\n",
    "                features = self.X[:, j]\n",
    "                v, direct, error, compare_array = self._G(features, self.Y, self.weights)\n",
    "                \n",
    "                if error < best_clf_error:\n",
    "                    best_clf_error = error\n",
    "                    best_v = v\n",
    "                    final_direct = direct\n",
    "                    clf_result = compare_array\n",
    "                    axis = j\n",
    "                    \n",
    "                # print('epoch:{}/{} feature:{} error:{} v:{}'.format(epoch, self.clf_num, j, error, best_v))\n",
    "                if best_clf_error == 0:\n",
    "                    break\n",
    "                \n",
    "            a = self._alpha(best_clf_error)\n",
    "            self.alpha.append(a)\n",
    "            # record clf\n",
    "            self.clf_sets.append((axis, best_v, final_direct))\n",
    "            Z = self._Z(self.weights, a, clf_result)\n",
    "            self._w(a, clf_result, Z)\n",
    "            \n",
    "    def predict(self, feature):\n",
    "        result = 0.0\n",
    "        for i in range(len(self.clf_sets)):\n",
    "            axis, clf_v, direct = self.clf_sets[i]\n",
    "            f_input = feature[axis]\n",
    "            result += self.alpha[i] * self.G(f_input, clf_v, direct)\n",
    "        # sign\n",
    "        return 1 if result > 0 else -1\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            feature = X_test[i]\n",
    "            if self.predict(feature) == y_test[i]:\n",
    "                right_count += 1\n",
    "        \n",
    "        return right_count / len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(10, 1)\n",
    "y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])\n",
    "clf = AdaBoost(n_estimators=3, learning_rate=0.5)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "clf = AdaBoost(n_estimators=10, learning_rate=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score:62.909%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# results after 100 iterations\n",
    "result = []\n",
    "for i in range(1, 101):\n",
    "    X, y = create_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf = AdaBoost(n_estimators=100, learning_rate=0.2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    r = clf.score(X_test, y_test)\n",
    "    # print('{}/100 score：{}'.format(i, r))\n",
    "    result.append(r)\n",
    "\n",
    "print('average score:{:.3f}%'.format(sum(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
